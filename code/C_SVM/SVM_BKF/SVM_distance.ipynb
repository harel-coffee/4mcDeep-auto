{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "3108\n",
      "[[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [1. 1. 1. ... 0. 1. 1.]\n",
      " ...\n",
      " [0. 1. 0. ... 1. 1. 0.]\n",
      " [1. 0. 0. ... 0. 1. 0.]\n",
      " [1. 0. 0. ... 0. 1. 1.]]\n",
      "[nan, nan, nan, nan, nan, 143.80698113072734, 143.80698113072734, 122.0748184988175, 122.0748184988175, 116.71771721821285, 116.71771721821285, 80.51101875044452, 80.51101875044452, 57.662759774667855, 57.662759774667855, 44.42361402133242, 44.42361402133242, 42.691822184464776, 40.919622610639784, 39.52048535463573, 39.52048535463573, 36.83400112942724, 36.83400112942724, 34.38376679867563, 32.51006015801747, 32.51006015801747, 28.76342487561347, 26.734404971569656, 25.760363247620173, 24.017553303977802, 23.997700842133526, 23.997700842133526, 21.716747967479517, 21.716747967479517, 20.99000513516652, 20.882007483683513, 20.882007483683513, 19.61220667420257, 18.39326780375128, 17.48245911980241, 17.48245911980241, 15.706431250877475, 15.706431250877475, 14.249413897190426, 14.249413897190426, 14.056797563234909, 12.98538412655949, 12.98538412655949, 12.829723599044913, 11.41640057837809, 11.41640057837809, 10.721166487291283, 10.721166487291283, 10.689051205307438, 10.4569735601739, 10.4569735601739, 7.45273603732801, 7.45273603732801, 7.350867686287448, 7.270447972368604, 7.270447972368604, 7.062889926847989, 7.062889926847989, 7.059665189578359, 6.497767725603482, 6.497767725603482, 6.326496678666693, 6.326496678666693, 5.791576430947979, 5.708258023360294, 5.61680441183046, 5.61680441183046, 5.128448550318096, 4.799256696993871, 4.799256696993871, 4.795401530057072, 4.795401530057072, 4.637628263087485, 4.637628263087485, 4.539764515486831, 4.516764101120003, 4.516764101120003, 4.4867592293651555, 4.4867592293651555, 4.069895591162533, 4.069895591162533, 4.0393533992987125, 4.0393533992987125, 4.039226094110708, 4.039226094110708, 3.7631027880822616, 3.7631027880822616, 3.6874280896275393, 3.5624452115224665, 3.3563577021220183, 3.3563577021220183, 3.355565856466716, 3.355565856466716, 3.349111224055722, 3.349111224055722, 3.276398956953242, 3.276398956953242, 3.094007980729471, 3.094007980729471, 3.091391533387055, 3.091391533387055, 3.0060062484324224, 2.8160310249066995, 2.4936824556893953, 2.4936824556893953, 2.2711040441435637, 2.2711040441435637, 2.2617073574985396, 2.180872170209371, 1.964849835923463, 1.964849835923463, 1.8585946655569754, 1.8585946655569754, 1.8584221578772695, 1.8584221578772695, 1.7103069308867898, 1.6697927244492425, 1.6697927244492425, 1.489750058087608, 1.489750058087608, 1.3197015163182686, 1.3197015163182686, 1.3176196094551242, 1.3176196094551242, 1.2698855865547534, 1.236545900904713, 1.236545900904713, 1.2365172146662768, 1.2365172146662768, 1.1743549653380507, 1.082246106907841, 1.082246106907841, 1.05765825013996, 1.0088543384272908, 1.0088543384272908, 1.008794155126313, 1.008794155126313, 0.9379223557228189, 0.9379223557228189, 0.8698708568721011, 0.8698708568721011, 0.6814516630737164, 0.6814516630737164, 0.6260021087387593, 0.6260021087387593, 0.6226366955814473, 0.6226366955814473, 0.5146576350269922, 0.5145757814724058, 0.5145757814724058, 0.41687544738710225, 0.41687544738710225, 0.3719828304264337, 0.3719828304264337, 0.3718041011218357, 0.3718041011218357, 0.30396185088059496, 0.29329346931471273, 0.2894687791238304, 0.2894687791238304, 0.24886087330184894, 0.23613213721233964, 0.18730620853012314, 0.18730620853012314, 0.18526416247896868, 0.18526416247896868, 0.13573488755060717, 0.12863030672483472, 0.12863030672483472, 0.06303527215163365, 0.06303527215163365, 0.06302441319141386, 0.06302441319141386, 0.062528054174134, 0.05321839348314126, 0.04926523284951904, 0.0489482614678782, 0.04696236754882239, 0.04635482651372363, 0.04635482651372363, 0.03559143473695541, 0.0321629845256778, 0.0321629845256778, 0.03215850893851969, 0.03215850893851969, 0.030381440651121604, 0.02062074688766673, 0.02062074688766673, 0.020579042306120832, 0.020579042306120832, 0.011582166927013656, 0.011577331722274369, 0.011577331722274369, 0.0012864554383411773, 0.0012864554383411773]\n",
      "[ 97  98 100 101   4 126 123 135 132 136 133 130 127 120 117 112 115 189\n",
      " 184  81  78 142 145 134 107 110 194 179 139 129 122 125 137 140 144 103\n",
      " 106 149 119 151 148 138 141 143 146 114 116 113  64 105 102  68  71   1\n",
      "  83  86 152 155  94  38  41  60  57 198  61  58 156 153 174   9 180 177\n",
      "  14   3   6  26  23  11   8  59  76  73 166 163  96  93 161 158  80  77\n",
      " 150 147 124  44  87  90  45  42 118 121  95  92 181 178  25  22 164 154\n",
      " 108 111 165 162  99  49 160 157  85  82 168 171 159 196 193 128 131  67\n",
      "  70  12  15 109  10   7 188 191  84  56  53  79  66  63  28  31 175 172\n",
      " 176 173  50  47  40  37  43  46 197  62  65  30  27  55  52  18  21  89\n",
      "  39   5   2  69  29  91  88  48  51  34  33  36  20  17  32  35 104  54\n",
      " 169 199  19 183 186  24 187 190 167 170  74  72  75  13  16   0 185 182\n",
      " 192 195]\n",
      "deal with data\n",
      "[126, 123, 135, 132, 136, 133, 130, 127, 120, 117, 112, 115, 189, 184, 81, 78, 142, 145, 134, 107, 110, 194, 179, 139, 129, 122, 125, 137, 140, 144, 103, 106, 149, 119, 151, 148, 138, 141, 143, 146, 114, 116, 113, 64, 105, 102, 68, 71, 1, 83, 86, 152, 155, 94, 38, 41, 60, 57, 198, 61, 58, 156, 153, 174, 9, 180, 177, 14, 3, 6, 26, 23, 11, 8, 59, 76, 73, 166, 163, 96, 93, 161, 158, 80, 77, 150, 147, 124, 44, 87, 90, 45, 42, 118, 121, 95, 92, 181, 178, 25, 22, 164, 154, 108, 111, 165, 162, 99, 49, 160, 157, 85, 82, 168, 171, 159, 196, 193, 128, 131, 67, 70, 12, 15, 109, 10, 7, 188, 191, 84, 56, 53, 79, 66, 63, 28, 31, 175, 172, 176, 173, 50, 47, 40, 37, 43, 46, 197, 62, 65, 30, 27, 55, 52, 18, 21, 89, 39, 5, 2, 69, 29, 91, 88, 48, 51, 34, 33, 36, 20, 17, 32, 35, 104, 54, 169, 199, 19, 183, 186, 24, 187, 190, 167, 170, 74, 72, 75, 13, 16, 0, 185, 182, 192, 195]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "# !/use/bin/env python\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "#from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import easy_excel\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import *\n",
    "import sklearn.ensemble\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import sys\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB  \n",
    "import subprocess\n",
    "from sklearn.utils import shuffle\n",
    "import itertools\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import sys\n",
    "from sklearn.feature_selection import  f_classif\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "path=\"../BKF/\"\n",
    "inputname='X_BKF.csv'\n",
    "outputname=inputname.split('.')[0]\n",
    "distance=10\n",
    "crossvalidation_values=3\n",
    "name=outputname\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "def performance(labelArr, predictArr):\n",
    "    #labelArr[i] is actual value,predictArr[i] is predict value\n",
    "    TP = 0.; TN = 0.; FP = 0.; FN = 0.\n",
    "    for i in range(len(labelArr)):\n",
    "        if labelArr[i] == 1 and predictArr[i] == 1:\n",
    "            TP += 1.\n",
    "        if labelArr[i] == 1 and predictArr[i] == 0:\n",
    "            FN += 1.\n",
    "        if labelArr[i] == 0 and predictArr[i] == 1:\n",
    "            FP += 1.\n",
    "        if labelArr[i] == 0 and predictArr[i] == 0:\n",
    "            TN += 1.\n",
    "    if (TP + FN)==0:\n",
    "        SN=0\n",
    "    else:\n",
    "        SN = TP/(TP + FN) #Sensitivity = TP/P  and P = TP + FN\n",
    "    if (FP+TN)==0:\n",
    "        SP=0\n",
    "    else:\n",
    "        SP = TN/(FP + TN) #Specificity = TN/N  and N = TN + FP\n",
    "    if (TP+FP)==0:\n",
    "        precision=0\n",
    "    else:\n",
    "        precision=TP/(TP+FP)\n",
    "    if (TP+FN)==0:\n",
    "        recall=0\n",
    "    else:\n",
    "        recall=TP/(TP+FN)\n",
    "    GM=math.sqrt(recall*SP)\n",
    "    #MCC = (TP*TN-FP*FN)/math.sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))\n",
    "    return precision,recall,SN,SP,GM,TP,TN,FP,FN\n",
    "\n",
    "#import pdb 调试\n",
    "#pdb.set_trace()\n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    # In[ ]:\n",
    "    \n",
    "    \"\"\"\n",
    "        cross validation and f-score and xgboost\n",
    "    \"\"\"\n",
    "    datapath =path+outputname+\".csv\"\n",
    "    classifier=\"SVM\"\n",
    "    mode=\"crossvalidation\"\n",
    "    print (\"start\")\n",
    "    train_data = pd.read_csv(datapath, header=None, index_col=None)\n",
    "    print (len(train_data))\n",
    "    Y = pd.read_csv('Y33.csv', header=None, index_col=None)\n",
    "    F, pval = f_classif(train_data, Y)\n",
    "    idx = np.argsort(F)\n",
    "    selected_list_=idx[::-1]\n",
    "    F_sort_value=[F[e] for e in selected_list_]\n",
    "    with open(classifier+mode+\"all_dimension_results.txt\",'w') as f:\n",
    "            f.write(str(F_sort_value)+\"\\n\")\n",
    "    print (F_sort_value)\n",
    "    with open(classifier+mode+\"all_dimension_results.txt\",'a') as f:\n",
    "            f.write(str(selected_list_)+\"\\n\")\n",
    "    print (selected_list_)\n",
    "    \n",
    "    print (\"deal with data\")\n",
    "    selected_list_=[a  for a,b in zip(selected_list_,F_sort_value) if not math.isnan(b)]\n",
    "    print (selected_list_)\n",
    "    \n",
    "    \n",
    "    bestACC=0\n",
    "    best_c=0\n",
    "    best_g=0\n",
    "    best_dimension=0\n",
    "    #bestlearning_rate=0\n",
    "    all_dimension_results=[]\n",
    "    select_list=[]\n",
    "    best_savedata=\"\"\n",
    "    select_num1=0;\n",
    "    for select_num in range(0,len(selected_list_),distance):\n",
    "        #print select_num\n",
    "        if select_num > 0:\n",
    "           #select_num1=select_num-9\n",
    "           #print select_num1\n",
    "            for select_num1 in range(select_num-distance+1,select_num+1):  \n",
    "               temp_data=selected_list_[select_num1]\n",
    "               select_list.append(int(temp_data))\n",
    "               train_data2=train_data.values\n",
    "               X_train=pd.DataFrame(train_data2)\n",
    "               X_train=X_train.iloc[:,select_list]\n",
    "               X = np.array(X_train)\n",
    "        else:\n",
    "            temp_data=selected_list_[select_num]\n",
    "            select_list.append(int(temp_data))\n",
    "            train_data2=train_data.values\n",
    "            X_train=pd.DataFrame(train_data2)\n",
    "            X_train=X_train.iloc[:,select_list]\n",
    "            X = np.array(X_train)\n",
    "        #print select_list\n",
    "        svc = svm.SVC(probability=True)\n",
    "        #parameters = {'kernel': ['rbf'], 'C': [math.pow(2,e) for e in range(-5,15,2)], 'gamma': [math.pow(2,e) for e in range(-15, -5, 2)]}\n",
    "        parameters = {'kernel': ['rbf'], 'C':list(map(lambda x:2**x,np.linspace(-2,5,7))), 'gamma':list(map(lambda x:2**x,np.linspace(-5,2,7)))}\n",
    "        clf = GridSearchCV(svc, parameters, cv=crossvalidation_values, scoring='accuracy')\n",
    "        clf.fit(X, Y)\n",
    "        C=clf.best_params_['C']\n",
    "        gamma=clf.best_params_['gamma']\n",
    "        #learning_rate=clf.best_params_['learning_rate']\n",
    "        # subsample=clf.best_params_['subsample']\n",
    "        # joblib.dump(clf,'/home02/chenhuangrong/'+name+'.model')\n",
    "        # print clf.best_score_\n",
    "        y_predict=cross_val_predict(svm.SVC(kernel='rbf',C=C,gamma=gamma),X,Y,cv=crossvalidation_values)\n",
    "        # y_predict=cross_val_predict(XGBClassifier(n_estimators=n_estimators,learning_rate=learning_rate,\n",
    "        #                                                        subsample=subsample,max_depth=max_depth),X,Y,cv=10,n_jobs=1)\n",
    "        y_predict_prob=cross_val_predict(svm.SVC(kernel='rbf',C=C,gamma=gamma,probability=True),X,Y,cv=crossvalidation_values,method='predict_proba')\n",
    "        \n",
    "        ##joblib.dump(clf,path+classifier+mode+outputname+str(select_num)+\".model\")\n",
    "        predict_save=[Y.astype(int),y_predict.astype(int),y_predict_prob[:,1]]\n",
    "        predict_save=np.array(predict_save).T\n",
    "        pd.DataFrame(predict_save).to_csv('Before_'+classifier+mode+outputname+\"_\"+'_predict_crossvalidation.csv',header=None,index=False)\n",
    "        ROC_AUC_area=metrics.roc_auc_score(Y,y_predict_prob[:,1])\n",
    "        ACC=metrics.accuracy_score(Y,y_predict)\n",
    "        precision, recall, SN, SP, GM, TP, TN, FP, FN = performance(Y, y_predict)\n",
    "        F1_Score=metrics.f1_score(Y, y_predict)\n",
    "        F_measure=F1_Score\n",
    "        MCC=metrics.matthews_corrcoef(Y, y_predict)\n",
    "        pos=TP+FN\n",
    "        neg=FP+TN\n",
    "        savedata=[[['SVM'+\"C:\"+str(C)+\"gamma:\"+str(gamma),ACC,precision, recall,SN, SP, GM,F_measure,F1_Score,MCC,ROC_AUC_area,TP,FN,FP,TN,pos,neg]]]\n",
    "        if ACC>bestACC:\n",
    "            bestACC=ACC\n",
    "            best_c=C\n",
    "            best_g=gamma\n",
    "            best_savedata=savedata\n",
    "            #bestmax_depth=max_depth\n",
    "            best_dimension=X.shape[1]\n",
    "        y_predict1=cross_val_predict(svm.SVC(kernel='rbf',C=best_c,gamma=best_g),X,Y,cv=crossvalidation_values)\n",
    "        y_predict_prob1=cross_val_predict(svm.SVC(kernel='rbf',C=best_c,gamma=best_g,probability=True),X,Y,cv=crossvalidation_values,method='predict_proba')\n",
    "        predict_save1=[Y.astype(int),y_predict1.astype(int),y_predict_prob1[:,1]]\n",
    "        predict_save1=np.array(predict_save1).T\n",
    "        pd.DataFrame(predict_save1).to_csv('After_'+classifier+mode+outputname+\"_\"+'_predict_crossvalidation.csv',header=None,index=False)\n",
    "        print (savedata)\n",
    "        print (X.shape[1])\n",
    "        with open(classifier+mode+\"all_dimension_results.txt\",'a') as f:\n",
    "            f.write(str(savedata)+\"\\n\")\n",
    "        all_dimension_results.append(savedata)\n",
    "    print (bestACC)\n",
    "    print (best_c)\n",
    "    print (best_g)\n",
    "    #print bestmax_depth\n",
    "    print (best_dimension)\n",
    "    selected_list_=selected_list_[0:best_dimension]\n",
    "    best_dimension_train_data=[train_data[e] for e in selected_list_]\n",
    "    best_dimension_train_data=np.array(best_dimension_train_data).T  \n",
    "    pd.DataFrame(best_dimension_train_data).to_csv('best_dimension_train_data.csv',header=None,index=False)    \n",
    "    easy_excel.save(\"SVM_crossvalidation\",[str(best_dimension)],best_savedata,classifier+mode+'cross_validation_'+name+'.xls')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    with open(\"all.txt\",'a') as f:\n",
    "            f.write(str(24234)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
