{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "3108\n",
      "[[1.         0.         0.         ... 0.         0.         0.        ]\n",
      " [1.         0.         0.         ... 0.         0.02631579 0.        ]\n",
      " [0.         0.         0.         ... 0.         0.02631579 0.        ]\n",
      " ...\n",
      " [0.         1.         0.         ... 0.         0.         0.02631579]\n",
      " [0.         0.         1.         ... 0.02631579 0.         0.02631579]\n",
      " [0.         0.         1.         ... 0.02631579 0.         0.        ]]\n",
      "[nan, nan, nan, nan, 403.11376771700526, 180.0335925631899, 139.06418867039034, 110.71173282843621, 106.61706299673644, 100.09367927977546, 92.46454607825854, 84.69198195177499, 80.20773556754277, 78.05294076140838, 77.50752293577989, 77.04837611556505, 75.95954981640004, 74.18112289578083, 69.89301846836969, 65.64812089077212, 65.09363919378542, 63.661492408930215, 63.26718831849349, 63.008101248640045, 61.72057431710246, 59.87765115516828, 59.789586248924685, 55.67814727141505, 55.18750803574498, 54.47453361110867, 54.19238917435007, 53.21470566904728, 52.296081930704354, 50.36747355285229, 47.9852081417179, 46.687290000047554, 46.14627408772258, 41.24657948520325, 40.79948144445796, 40.31603221993469, 39.68208768538528, 39.160452971111795, 38.69663516440514, 37.77525030875259, 37.77021845512715, 37.61527357065742, 36.92577700971744, 36.292132150837766, 35.644225816850124, 35.53511248313505, 35.391644610384404, 34.98493901020883, 34.960173772059036, 34.5561238134813, 34.55026172908448, 33.37050899876231, 33.169561633649, 33.0942052505411, 32.13091483591233, 32.07842027965213, 31.232423627962362, 30.963993806151556, 30.558843993012925, 30.386845063397033, 30.22195193933156, 30.210796039554705, 30.09166361016499, 28.81276077228988, 28.64768536785627, 27.647400260099694, 27.614133069488688, 27.25127979264778, 27.123102752131896, 26.99236126670999, 26.45173957990832, 24.957361657908642, 24.047461431860963, 23.279368192846785, 22.87524474891613, 22.86579524506442, 22.79303548283742, 22.642028741859605, 22.602221839476442, 22.241245939289154, 20.310640650046892, 20.1944584440757, 20.157931165260138, 19.909538699110758, 19.720324445507927, 19.58634328358196, 19.540683673473897, 19.51945521696536, 19.35597522687017, 19.262217354078174, 19.226124305204582, 19.20068989103694, 18.890573205981354, 18.86269924424311, 18.798989728525328, 18.474627549581704, 18.326137139790344, 18.299799112115142, 17.95478559010004, 17.79529843658261, 17.365339150913435, 17.233569211389664, 17.125204872803998, 16.923979994735358, 16.89290321945269, 16.88458107636415, 16.760043628560155, 16.68340283909764, 16.479346798439135, 16.4391507955998, 16.2874248906968, 16.112207396397352, 15.810326812127123, 15.60427727603902, 15.524043809315422, 15.46641548978371, 14.820208974712997, 14.710029631607945, 14.573562346967426, 14.365419081437867, 14.199009400312399, 14.186673563829375, 14.148926429708881, 14.088454007103104, 13.921075081342973, 13.871686158683035, 13.715804889039198, 13.542036411292923, 13.533092899933441, 13.121852944205159, 13.079482336928477, 12.857808699381216, 12.749086074500175, 12.642963811066325, 12.383493301620605, 12.315140241813385, 12.273353354257438, 12.127439195235, 11.978809367700478, 11.920573502291631, 11.890433099930457, 11.832774666489145, 11.711464758319849, 11.612868479991764, 11.464466767967794, 11.389398149506636, 11.327287757986761, 11.320586106620725, 11.292839158022279, 11.292505059796824, 11.043231563878866, 10.918029672005725, 10.907137638247475, 10.905363190539042, 10.871610466408015, 10.554011292295636, 10.470324615684042, 10.23206208087883, 10.2088280227592, 10.184910977327988, 10.070653498953446, 9.962834108400235, 9.870749534419456, 9.738203480169263, 9.63171548388518, 9.566647224154853, 9.504930295817752, 9.455103539776035, 9.422436677812852, 9.410366036006687, 9.33375654777217, 9.283413843931006, 9.192974557787851, 9.187174633223037, 9.162054851846984, 9.15105907457771, 9.07879180159107, 9.05563970528812, 9.047736695568668, 8.999586882091615, 8.902040036765943, 8.82179240411265, 8.721761062312174, 8.654294083015367, 8.57904317439455, 8.547630010913796, 8.447407779928872, 8.33248800117367, 8.297169456639983, 8.252643378126898, 8.21906246278881, 8.00098611638682, 7.757727130815069, 7.511897976508794, 7.193779853677303, 7.078345998094204, 7.071480122882537, 7.014136378623582, 6.929532030714521, 6.87064278273646, 6.8281019677979575, 6.819912390602425, 6.7958018529281405, 6.707331244310832, 6.629311831666147, 6.613399708307588, 6.543129919143143, 6.504942404473434, 6.4989324919835365, 6.333020055115897, 6.314671604663671, 6.312711221000094, 6.287385258167375, 6.166844150786079, 6.121702360552658, 6.018182499851646, 6.011183187691, 5.822503620318642, 5.807539049427687, 5.804112820499049, 5.789585104050118, 5.735652373446635, 5.592708569040136, 5.592152946650828, 5.496793402806818, 5.422091152538042, 5.418428292932356, 5.410134199367983, 5.387751605689498, 5.379124726116849, 5.349292803168913, 5.227495998124931, 5.191159825641306, 5.164417727185419, 5.156528785957375, 5.132243087722309, 5.111227990970752, 5.106846499678772, 5.0661695454032, 5.055905802450881, 5.051661433508766, 5.0377111279882225, 4.943794258772825, 4.841598450435134, 4.833147266104861, 4.772152449445443, 4.63915472700111, 4.485547161958441, 4.47420725503232, 4.432868305562524, 4.411284915862061, 4.40641790220418, 4.3651071561720425, 4.3651071561720425, 4.334841321216765, 4.3235383683808415, 4.250505083222346, 4.201559566678866, 4.193834851683502, 4.185086334685153, 4.045569474895257, 4.03424525361086, 4.00742535151919, 3.9880841837754404, 3.967959937146201, 3.9228290847229195, 3.875615210456378, 3.8726428390699463, 3.815184754587284, 3.76257129698213, 3.7548378586037847, 3.7050952693696577, 3.6614421621593007, 3.604545411483836, 3.5102495717939513, 3.488847626252278, 3.439110049999194, 3.3761873785139755, 3.3522886551665887, 3.299767967034175, 3.297862005844681, 3.2436122122288267, 3.1421651961138366, 3.118249652906436, 2.9776477117917426, 2.960891700907356, 2.9606352557488784, 2.90996607437765, 2.8013463179901876, 2.790836479850282, 2.7592644626178586, 2.637966178468982, 2.630593379552111, 2.609489550157599, 2.5532992880006424, 2.497937590515075, 2.4833695791224835, 2.338271978903109, 2.329782606765833, 2.302012975921361, 2.296214816880147, 2.2848284096316336, 2.2607630004566226, 2.1737552962630424, 2.1550921811456933, 2.154083784115049, 2.1391292186552056, 2.1312690809771495, 2.122015621249485, 2.114038619982661, 2.1137384431721493, 2.1083342346253593, 2.101966363507901, 2.0841387179653537, 2.043190192098154, 2.019603311074985, 2.011223829052519, 2.0027862249041584, 1.9397429948087068, 1.9154261292537857, 1.9105808042337709, 1.8440485323508673, 1.8319980339149196, 1.8067795178115058, 1.7916474388555146, 1.7872400302257387, 1.7736437355758001, 1.7570023932103092, 1.7554830208618646, 1.7390539595885546, 1.7049113938873053, 1.667713907895832, 1.6595071701822777, 1.6524450618469746, 1.627536065761723, 1.5680525040116975, 1.55075151666243, 1.5228992385079914, 1.5197907483986588, 1.5112516725458927, 1.5008974181967993, 1.4956621345486103, 1.463251877634197, 1.4417073894962769, 1.4187889976702974, 1.3650581480017723, 1.347921932229943, 1.3029817105863515, 1.279257348686845, 1.2757975446123173, 1.239583665911057, 1.2239020799527358, 1.2011870279315764, 1.1975540742062616, 1.162874980381568, 1.1508264386256968, 1.1466896381985017, 1.1228562339128225, 1.120664638828991, 1.1203409303446625, 1.1121396175370537, 1.0643428174378706, 1.0291242834896703, 1.0184162016955651, 0.9757588837390928, 0.9490795267407497, 0.9454281720203572, 0.919149742099464, 0.9099102315866292, 0.8890231685405495, 0.8777814590519323, 0.8710066323732792, 0.8668427754379413, 0.8530097787569813, 0.8460781791494033, 0.8311397423192244, 0.8247580086383132, 0.8196267083253258, 0.8192797173632309, 0.7498403856283586, 0.7369332185366101, 0.72262140757223, 0.7178841646626357, 0.6833215184922119, 0.6827721102167739, 0.6819046689758591, 0.6683893311365592, 0.6622095762517123, 0.6269832939029755, 0.6116988220302253, 0.6001875666660492, 0.5914684502099197, 0.5807247737678887, 0.5701614036360133, 0.5524642407174498, 0.5519687465849291, 0.543544176312389, 0.5385101104693253, 0.5334842945425621, 0.5269086147384031, 0.4805209417456328, 0.46631755073085573, 0.44658861003954536, 0.4430206419662813, 0.43958083041370666, 0.42916757283548895, 0.4221595268464984, 0.4183081643224978, 0.4136874973401365, 0.41053130128622006, 0.4079796800605042, 0.40572624395178436, 0.4035862785862261, 0.38934321783686243, 0.38317488771167, 0.3819641641173684, 0.37891269650327347, 0.35163591078908135, 0.3507638656753564, 0.3501108671886764, 0.3492081417441052, 0.3373480501161767, 0.33201512299567676, 0.2946131139828975, 0.271967366532374, 0.2643584244032962, 0.25904992190437065, 0.258583794650747, 0.25775022317463, 0.25472334453654777, 0.23658775580829405, 0.22993078081738821, 0.22349544428361362, 0.20901645473080177, 0.2064593321312788, 0.195302675131131, 0.19438468579109408, 0.193978061618243, 0.18805152345343232, 0.18797256968212908, 0.1863630187728752, 0.17970767127841972, 0.17783185128201606, 0.17588637614550745, 0.17131485530343615, 0.16783745812171888, 0.16611457814524846, 0.15657543741743452, 0.14680083106821376, 0.1341497943650779, 0.1310489815009652, 0.1292739816087738, 0.12908714319394662, 0.1174601974056526, 0.11295031622878723, 0.10327629012227489, 0.10205143541461409, 0.09873381668191868, 0.09784010419553711, 0.09648160036447427, 0.09515348324260756, 0.0910809840733571, 0.08649208594626695, 0.0857674087528552, 0.08349588058312712, 0.07623964437461501, 0.07280317892123504, 0.06922985023522255, 0.06806471802008379, 0.06559196644126498, 0.06267990707389376, 0.06140888511042259, 0.04530819491916884, 0.04056673266715093, 0.03941620363835545, 0.03572734034911998, 0.02545249679888633, 0.025081424456859725, 0.024327393773167002, 0.023366647984417975, 0.018890160817076673, 0.018242044800552137, 0.014944259739445574, 0.013809340793497127, 0.012512437911199607, 0.012499924541736452, 0.010899239930698275, 0.009872760272363989, 0.008093452537668413, 0.006889255113053434, 0.00500122910641304, 0.004382765262710901, 0.0023919354962257983, 0.002164505181300524, 0.0015213602704332017, -1.3566639989608375e-13]\n",
      "[ 80  81  83  82 110 174 223  97 103 241 222 106  93 108  99 177 118 183\n",
      " 111 190 175 104 195 247 259  85 179 415 497 100 102 307 166 176 243 286\n",
      " 232  91 437 416 146 478 230 419 418 254 123 491 238 115 382 414 412 351\n",
      " 206 488 226  89 167 320 265  67 499 201 196 193  78 180 287 398 430 164\n",
      " 305 214 460 479 308 452 124 228 486 340   2  50 454 221 350  73 417  94\n",
      " 224 413 235  34 441 290 229 446 109 410 372 182 191 311 369 298 220 438\n",
      " 122 356 244 168 169 116 468 375   3 227 296 234  66 204 218  39 278 257\n",
      " 456  22 489 328 154 144 431 493 212  75 422 155 329 292 458 316 208 192\n",
      " 406 353 293 490  64 421  26 432 467 387 330 263 466 434 463 112  54 448\n",
      " 409 447 364  76 321  95 147 240  37 185 498 306 128  61 472 150 117 368\n",
      "  79 332 282 443 425 132 149 151  35 294 207 272 492 343  86 374 158 331\n",
      "  46 465 371  59 236 249 163 470 107 237  68 159  60 349 444 148 153 126\n",
      "   7 284 494 404 400 271  71 388 303 291 233  10 285 453  27 239 211 323\n",
      " 270 428 457 471 125 445  72 302 260 355 113  84 482 242 383  56  55   6\n",
      " 253 462 152 162  30 101 215 173 455 289 140 380 338 393 389 334 319 359\n",
      " 189 225 256 216  24  14  38 450 396  74  96 129 209 485  52 385 274 326\n",
      " 360  49  47 203 178   9 344 420 245 198 133 297  31 366  12  65  58 194\n",
      " 210 449 251 119 304 440 231 165 171 317  28  88 363 121  48 384 358  25\n",
      " 309 283 487 217  29 439  23 114 322 157 105  51 264 407  44  69 255  21\n",
      " 315 145 299 246  42 324 342 142 261  53  57 130 141  70 156 480 275 367\n",
      "  87 348 276  19 160 341 481  77 390 197 301 381 336 135 188 403 136 339\n",
      " 435 262 266  18 219  11 137  20 120 300  36 127 202 134  32 427 373 213\n",
      " 473 258 352 139 362 483 408 442 405 200 277  45 464 346 477 345 279 401\n",
      " 397 459 138 426 476 411 268 361 423  40 131 184 248 250 170 295 327 461\n",
      "   0   4 469 181 318 310 365  17 281   1 391 378  15 314 475 172 252  62\n",
      " 273 496 354 429 484 376 386  41 370 288 161 399  13 392  90 377 269 395\n",
      " 379   8 199 333 433 335 394 325 313 495  63 347  43 424  92 312  98 337\n",
      " 474  16 402 186 267 205   5  33 187 451 357 280 143 436]\n",
      "deal with data\n",
      "[110, 174, 223, 97, 103, 241, 222, 106, 93, 108, 99, 177, 118, 183, 111, 190, 175, 104, 195, 247, 259, 85, 179, 415, 497, 100, 102, 307, 166, 176, 243, 286, 232, 91, 437, 416, 146, 478, 230, 419, 418, 254, 123, 491, 238, 115, 382, 414, 412, 351, 206, 488, 226, 89, 167, 320, 265, 67, 499, 201, 196, 193, 78, 180, 287, 398, 430, 164, 305, 214, 460, 479, 308, 452, 124, 228, 486, 340, 2, 50, 454, 221, 350, 73, 417, 94, 224, 413, 235, 34, 441, 290, 229, 446, 109, 410, 372, 182, 191, 311, 369, 298, 220, 438, 122, 356, 244, 168, 169, 116, 468, 375, 3, 227, 296, 234, 66, 204, 218, 39, 278, 257, 456, 22, 489, 328, 154, 144, 431, 493, 212, 75, 422, 155, 329, 292, 458, 316, 208, 192, 406, 353, 293, 490, 64, 421, 26, 432, 467, 387, 330, 263, 466, 434, 463, 112, 54, 448, 409, 447, 364, 76, 321, 95, 147, 240, 37, 185, 498, 306, 128, 61, 472, 150, 117, 368, 79, 332, 282, 443, 425, 132, 149, 151, 35, 294, 207, 272, 492, 343, 86, 374, 158, 331, 46, 465, 371, 59, 236, 249, 163, 470, 107, 237, 68, 159, 60, 349, 444, 148, 153, 126, 7, 284, 494, 404, 400, 271, 71, 388, 303, 291, 233, 10, 285, 453, 27, 239, 211, 323, 270, 428, 457, 471, 125, 445, 72, 302, 260, 355, 113, 84, 482, 242, 383, 56, 55, 6, 253, 462, 152, 162, 30, 101, 215, 173, 455, 289, 140, 380, 338, 393, 389, 334, 319, 359, 189, 225, 256, 216, 24, 14, 38, 450, 396, 74, 96, 129, 209, 485, 52, 385, 274, 326, 360, 49, 47, 203, 178, 9, 344, 420, 245, 198, 133, 297, 31, 366, 12, 65, 58, 194, 210, 449, 251, 119, 304, 440, 231, 165, 171, 317, 28, 88, 363, 121, 48, 384, 358, 25, 309, 283, 487, 217, 29, 439, 23, 114, 322, 157, 105, 51, 264, 407, 44, 69, 255, 21, 315, 145, 299, 246, 42, 324, 342, 142, 261, 53, 57, 130, 141, 70, 156, 480, 275, 367, 87, 348, 276, 19, 160, 341, 481, 77, 390, 197, 301, 381, 336, 135, 188, 403, 136, 339, 435, 262, 266, 18, 219, 11, 137, 20, 120, 300, 36, 127, 202, 134, 32, 427, 373, 213, 473, 258, 352, 139, 362, 483, 408, 442, 405, 200, 277, 45, 464, 346, 477, 345, 279, 401, 397, 459, 138, 426, 476, 411, 268, 361, 423, 40, 131, 184, 248, 250, 170, 295, 327, 461, 0, 4, 469, 181, 318, 310, 365, 17, 281, 1, 391, 378, 15, 314, 475, 172, 252, 62, 273, 496, 354, 429, 484, 376, 386, 41, 370, 288, 161, 399, 13, 392, 90, 377, 269, 395, 379, 8, 199, 333, 433, 335, 394, 325, 313, 495, 63, 347, 43, 424, 92, 312, 98, 337, 474, 16, 402, 186, 267, 205, 5, 33, 187, 451, 357, 280, 143, 436]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Before_../BKF/SVMcrossvalidationBKF__predict_crossvalidation.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-bdfa0d7d2319>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    163\u001b[0m         \u001b[0mpredict_save\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_predict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_predict_prob\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m         \u001b[0mpredict_save\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict_save\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 165\u001b[1;33m         \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict_save\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Before_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0moutputname\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"_\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_predict_crossvalidation.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    166\u001b[0m         \u001b[0mROC_AUC_area\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_predict_prob\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m         \u001b[0mACC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_predict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[0;32m   3018\u001b[0m                                  \u001b[0mdoublequote\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3019\u001b[0m                                  escapechar=escapechar, decimal=decimal)\n\u001b[1;32m-> 3020\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3021\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3022\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    155\u001b[0m             f, handles = _get_handle(self.path_or_buf, self.mode,\n\u001b[0;32m    156\u001b[0m                                      \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 157\u001b[1;33m                                      compression=self.compression)\n\u001b[0m\u001b[0;32m    158\u001b[0m             \u001b[0mclose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[0;32m    422\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m             \u001b[1;31m# Python 3 and encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 424\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    425\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m             \u001b[1;31m# Python 3 and no explicit encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Before_../BKF/SVMcrossvalidationBKF__predict_crossvalidation.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "# !/use/bin/env python\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "#from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import easy_excel\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import *\n",
    "import sklearn.ensemble\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import sys\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB  \n",
    "import subprocess\n",
    "from sklearn.utils import shuffle\n",
    "import itertools\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import sys\n",
    "from sklearn.feature_selection import  f_classif\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "path=\"../KNN/\"\n",
    "inputname='KNN.csv'\n",
    "outputname=inputname.split('.')[0]\n",
    "distance=10\n",
    "crossvalidation_values=10\n",
    "name=outputname\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "def performance(labelArr, predictArr):\n",
    "    #labelArr[i] is actual value,predictArr[i] is predict value\n",
    "    TP = 0.; TN = 0.; FP = 0.; FN = 0.\n",
    "    for i in range(len(labelArr)):\n",
    "        if labelArr[i] == 1 and predictArr[i] == 1:\n",
    "            TP += 1.\n",
    "        if labelArr[i] == 1 and predictArr[i] == 0:\n",
    "            FN += 1.\n",
    "        if labelArr[i] == 0 and predictArr[i] == 1:\n",
    "            FP += 1.\n",
    "        if labelArr[i] == 0 and predictArr[i] == 0:\n",
    "            TN += 1.\n",
    "    if (TP + FN)==0:\n",
    "        SN=0\n",
    "    else:\n",
    "        SN = TP/(TP + FN) #Sensitivity = TP/P  and P = TP + FN\n",
    "    if (FP+TN)==0:\n",
    "        SP=0\n",
    "    else:\n",
    "        SP = TN/(FP + TN) #Specificity = TN/N  and N = TN + FP\n",
    "    if (TP+FP)==0:\n",
    "        precision=0\n",
    "    else:\n",
    "        precision=TP/(TP+FP)\n",
    "    if (TP+FN)==0:\n",
    "        recall=0\n",
    "    else:\n",
    "        recall=TP/(TP+FN)\n",
    "    GM=math.sqrt(recall*SP)\n",
    "    #MCC = (TP*TN-FP*FN)/math.sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))\n",
    "    return precision,recall,SN,SP,GM,TP,TN,FP,FN\n",
    "\n",
    "#import pdb 调试\n",
    "#pdb.set_trace()\n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    # In[ ]:\n",
    "    \n",
    "    \"\"\"\n",
    "        cross validation and f-score and xgboost\n",
    "    \"\"\"\n",
    "    datapath =path+outputname+\".csv\"\n",
    "    classifier=\"SVM\"\n",
    "    mode=\"crossvalidation\"\n",
    "    print (\"start\")\n",
    "    train_data = pd.read_csv(datapath, header=None, index_col=None)\n",
    "    print (len(train_data))\n",
    "    print (train_data.values[:,0:-1])\n",
    "    Y = list(map(lambda x: 1, range(len(train_data) // 2)))\n",
    "    Y2 = list(map(lambda x: 0, range(len(train_data) // 2)))\n",
    "    Y.extend(Y2)\n",
    "    Y = np.array(Y)\n",
    "    F, pval = f_classif(train_data, Y)\n",
    "    idx = np.argsort(F)\n",
    "    selected_list_=idx[::-1]\n",
    "    F_sort_value=[F[e] for e in selected_list_]\n",
    "    with open(classifier+mode+\"all_dimension_results.txt\",'w') as f:\n",
    "            f.write(str(F_sort_value)+\"\\n\")\n",
    "    print (F_sort_value)\n",
    "    with open(classifier+mode+\"all_dimension_results.txt\",'a') as f:\n",
    "            f.write(str(selected_list_)+\"\\n\")\n",
    "    print (selected_list_)\n",
    "    \n",
    "    print (\"deal with data\")\n",
    "    selected_list_=[a  for a,b in zip(selected_list_,F_sort_value) if not math.isnan(b)]\n",
    "    print (selected_list_)\n",
    "    \n",
    "    \n",
    "    bestACC=0\n",
    "    best_c=0\n",
    "    best_g=0\n",
    "    best_dimension=0\n",
    "    #bestlearning_rate=0\n",
    "    all_dimension_results=[]\n",
    "    select_list=[]\n",
    "    best_savedata=\"\"\n",
    "    select_num1=0;\n",
    "    for select_num in range(0,len(selected_list_),distance):\n",
    "        #print select_num\n",
    "        if select_num > 0:\n",
    "           #select_num1=select_num-9\n",
    "           #print select_num1\n",
    "            for select_num1 in range(select_num-distance+1,select_num+1):  \n",
    "               temp_data=selected_list_[select_num1]\n",
    "               select_list.append(int(temp_data))\n",
    "               train_data2=train_data.values\n",
    "               X_train=pd.DataFrame(train_data2)\n",
    "               X_train=X_train.iloc[:,select_list]\n",
    "               X = np.array(X_train)\n",
    "        else:\n",
    "            temp_data=selected_list_[select_num]\n",
    "            select_list.append(int(temp_data))\n",
    "            train_data2=train_data.values\n",
    "            X_train=pd.DataFrame(train_data2)\n",
    "            X_train=X_train.iloc[:,select_list]\n",
    "            X = np.array(X_train)\n",
    "        #print select_list\n",
    "        svc = svm.SVC(probability=True)\n",
    "        #parameters = {'kernel': ['rbf'], 'C': [math.pow(2,e) for e in range(-5,15,2)], 'gamma': [math.pow(2,e) for e in range(-15, -5, 2)]}\n",
    "        parameters = {'kernel': ['rbf'], 'C':list(map(lambda x:2**x,np.linspace(-2,5,7))), 'gamma':list(map(lambda x:2**x,np.linspace(-5,2,7)))}\n",
    "        clf = GridSearchCV(svc, parameters, cv=crossvalidation_values, scoring='accuracy')\n",
    "        clf.fit(X, Y)\n",
    "        C=clf.best_params_['C']\n",
    "        gamma=clf.best_params_['gamma']\n",
    "        #learning_rate=clf.best_params_['learning_rate']\n",
    "        # subsample=clf.best_params_['subsample']\n",
    "        # joblib.dump(clf,'/home02/chenhuangrong/'+name+'.model')\n",
    "        # print clf.best_score_\n",
    "        y_predict=cross_val_predict(svm.SVC(kernel='rbf',C=C,gamma=gamma),X,Y,cv=crossvalidation_values)\n",
    "        # y_predict=cross_val_predict(XGBClassifier(n_estimators=n_estimators,learning_rate=learning_rate,\n",
    "        #                                                        subsample=subsample,max_depth=max_depth),X,Y,cv=10,n_jobs=1)\n",
    "        y_predict_prob=cross_val_predict(svm.SVC(kernel='rbf',C=C,gamma=gamma,probability=True),X,Y,cv=crossvalidation_values,method='predict_proba')\n",
    "        \n",
    "        ##joblib.dump(clf,path+classifier+mode+outputname+str(select_num)+\".model\")\n",
    "        predict_save=[Y.astype(int),y_predict.astype(int),y_predict_prob[:,1]]\n",
    "        predict_save=np.array(predict_save).T\n",
    "        pd.DataFrame(predict_save).to_csv('Before_'+classifier+mode+outputname+\"_\"+'_predict_crossvalidation.csv',header=None,index=False)\n",
    "        ROC_AUC_area=metrics.roc_auc_score(Y,y_predict_prob[:,1])\n",
    "        ACC=metrics.accuracy_score(Y,y_predict)\n",
    "        precision, recall, SN, SP, GM, TP, TN, FP, FN = performance(Y, y_predict)\n",
    "        F1_Score=metrics.f1_score(Y, y_predict)\n",
    "        F_measure=F1_Score\n",
    "        MCC=metrics.matthews_corrcoef(Y, y_predict)\n",
    "        pos=TP+FN\n",
    "        neg=FP+TN\n",
    "        savedata=[[['SVM'+\"C:\"+str(C)+\"gamma:\"+str(gamma),ACC,precision, recall,SN, SP, GM,F_measure,F1_Score,MCC,ROC_AUC_area,TP,FN,FP,TN,pos,neg]]]\n",
    "        if ACC>bestACC:\n",
    "            bestACC=ACC\n",
    "            best_c=C\n",
    "            best_g=gamma\n",
    "            best_savedata=savedata\n",
    "            #bestmax_depth=max_depth\n",
    "            best_dimension=X.shape[1]\n",
    "        y_predict1=cross_val_predict(svm.SVC(kernel='rbf',C=best_c,gamma=best_g),X,Y,cv=crossvalidation_values)\n",
    "        y_predict_prob1=cross_val_predict(svm.SVC(kernel='rbf',C=best_c,gamma=best_g,probability=True),X,Y,cv=crossvalidation_values,method='predict_proba')\n",
    "        predict_save1=[Y.astype(int),y_predict1.astype(int),y_predict_prob1[:,1]]\n",
    "        predict_save1=np.array(predict_save1).T\n",
    "        pd.DataFrame(predict_save1).to_csv('After_'+classifier+mode+outputname+\"_\"+'_predict_crossvalidation.csv',header=None,index=False)\n",
    "        print (savedata)\n",
    "        print (X.shape[1])\n",
    "        with open(classifier+mode+\"all_dimension_results.txt\",'a') as f:\n",
    "            f.write(str(savedata)+\"\\n\")\n",
    "        all_dimension_results.append(savedata)\n",
    "    print (bestACC)\n",
    "    print (best_c)\n",
    "    print (best_g)\n",
    "    #print bestmax_depth\n",
    "    print (best_dimension)\n",
    "    selected_list_=selected_list_[0:best_dimension]\n",
    "    best_dimension_train_data=[train_data[e] for e in selected_list_]\n",
    "    best_dimension_train_data=np.array(best_dimension_train_data).T  \n",
    "    pd.DataFrame(best_dimension_train_data).to_csv('best_dimension_train_data.csv',header=None,index=False)    \n",
    "    easy_excel.save(\"SVM_crossvalidation\",[str(best_dimension)],best_savedata,classifier+mode+'cross_validation_'+name+'.xls')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
